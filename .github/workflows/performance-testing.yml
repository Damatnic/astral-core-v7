name: 'Performance Testing'

on:
  schedule:
    # Run performance tests daily at 3 AM UTC
    - cron: '0 3 * * *'
  push:
    branches: ['main', 'master']
    paths:
      - 'src/**'
      - 'package*.json'
      - 'next.config.*'
      - 'tsconfig.json'
  pull_request:
    branches: ['main', 'master']
    paths:
      - 'src/**'
      - 'package*.json'
      - 'next.config.*'
      - 'tsconfig.json'
    types: [opened, synchronize, reopened]
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of performance test to run'
        required: true
        default: 'full'
        type: choice
        options:
          - 'full'
          - 'lighthouse-only'
          - 'load-test-only'
          - 'bundle-analysis-only'
      test_duration:
        description: 'Load test duration (minutes)'
        required: false
        default: '5'
        type: string

# Cancel previous runs for the same workflow
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  NODE_VERSION: '18.17'

jobs:
  # Build application for performance testing
  build-for-testing:
    name: 'Build Application'
    runs-on: ubuntu-latest
    
    outputs:
      build-time: ${{ steps.build-timer.outputs.build-time }}
      
    steps:
      - name: 'Checkout Code'
        uses: actions/checkout@v5

      - name: 'Setup Node.js'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 'Install Dependencies'
        run: |
          npm ci --prefer-offline --no-audit --no-fund

      - name: 'Generate Prisma Client'
        run: |
          npm run db:generate
        env:
          DATABASE_URL: "postgresql://test:test@localhost:5432/testdb"

      - name: 'Build Application with Timing'
        id: build-timer
        run: |
          start_time=$(date +%s)
          npm run build
          end_time=$(date +%s)
          build_time=$((end_time - start_time))
          echo "build-time=${build_time}" >> $GITHUB_OUTPUT
          echo "Build completed in ${build_time} seconds"
        env:
          DATABASE_URL: "postgresql://test:test@localhost:5432/testdb"
          NEXTAUTH_SECRET: "test-secret-for-ci"
          NEXTAUTH_URL: "http://localhost:3000"
          SKIP_ENV_VALIDATION: true

      - name: 'Cache Build Output'
        uses: actions/cache@v3
        with:
          path: |
            .next
            node_modules
          key: build-cache-${{ runner.os }}-${{ github.sha }}
          restore-keys: |
            build-cache-${{ runner.os }}-

      - name: 'Upload Build Artifacts'
        uses: actions/upload-artifact@v4
        with:
          name: build-output
          path: |
            .next
            package.json
            next.config.*
          retention-days: 1

  # Bundle size analysis
  bundle-analysis:
    name: 'Bundle Size Analysis'
    runs-on: ubuntu-latest
    needs: [build-for-testing]
    if: github.event.inputs.test_type != 'lighthouse-only' && github.event.inputs.test_type != 'load-test-only'
    
    steps:
      - name: 'Checkout Code'
        uses: actions/checkout@v5

      - name: 'Setup Node.js'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 'Download Build Artifacts'
        uses: actions/download-artifact@v4
        with:
          name: build-output

      - name: 'Install Bundle Analyzer'
        run: |
          npm install --no-save @next/bundle-analyzer webpack-bundle-analyzer

      - name: 'Analyze Bundle Size'
        run: |
          npx next-bundle-analysis
          
          # Generate detailed bundle report
          echo "# Bundle Analysis Report" > bundle-report.md
          echo "" >> bundle-report.md
          echo "**Build Time:** ${{ needs.build-for-testing.outputs.build-time }} seconds" >> bundle-report.md
          echo "**Date:** $(date -u)" >> bundle-report.md
          echo "" >> bundle-report.md
          
          # Extract bundle sizes (this would need to be customized based on actual output)
          if [ -f ".next/analyze/client.html" ]; then
            echo "✅ Client bundle analysis completed" >> bundle-report.md
          fi
          if [ -f ".next/analyze/nodejs.html" ]; then
            echo "✅ Server bundle analysis completed" >> bundle-report.md
          fi

      - name: 'Compare Bundle Sizes'
        uses: nextjs-bundle-analysis/bundle-analysis-action@v1
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          workflow-id: 'performance-testing.yml'
          skip-build: true

      - name: 'Upload Bundle Analysis'
        uses: actions/upload-artifact@v4
        with:
          name: bundle-analysis
          path: |
            .next/analyze/
            bundle-report.md
          retention-days: 30

  # Lighthouse performance testing
  lighthouse-testing:
    name: 'Lighthouse Performance'
    runs-on: ubuntu-latest
    needs: [build-for-testing]
    if: github.event.inputs.test_type != 'load-test-only' && github.event.inputs.test_type != 'bundle-analysis-only'
    
    strategy:
      matrix:
        page: ['/', '/dashboard', '/login', '/register']
    
    steps:
      - name: 'Checkout Code'
        uses: actions/checkout@v5

      - name: 'Setup Node.js'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 'Install Dependencies'
        run: npm ci --prefer-offline --no-audit --no-fund

      - name: 'Download Build Artifacts'
        uses: actions/download-artifact@v4
        with:
          name: build-output

      - name: 'Setup Test Database'
        run: |
          docker run --name perf-test-postgres -e POSTGRES_USER=test -e POSTGRES_PASSWORD=test -e POSTGRES_DB=testdb -p 5432:5432 -d postgres:15-alpine
          sleep 10

      - name: 'Start Application'
        run: |
          npm start &
          sleep 30
          curl -f http://localhost:3000/api/health || exit 1
        env:
          DATABASE_URL: "postgresql://test:test@localhost:5432/testdb"
          NEXTAUTH_SECRET: "test-secret-for-ci"
          NEXTAUTH_URL: "http://localhost:3000"
          PORT: 3000

      - name: 'Run Lighthouse Performance Test'
        uses: treosh/lighthouse-ci-action@v10
        with:
          urls: |
            http://localhost:3000${{ matrix.page }}
          configPath: '.github/lighthouse/performance.json'
          uploadArtifacts: true
          temporaryPublicStorage: true

      - name: 'Store Lighthouse Results'
        uses: actions/upload-artifact@v4
        with:
          name: lighthouse-results-${{ matrix.page == '/' && 'home' || matrix.page }}
          path: |
            .lighthouseci/
            lighthouse-results.json
          retention-days: 30

  # Load testing
  load-testing:
    name: 'Load Testing'
    runs-on: ubuntu-latest
    needs: [build-for-testing]
    if: github.event.inputs.test_type != 'lighthouse-only' && github.event.inputs.test_type != 'bundle-analysis-only'
    
    strategy:
      matrix:
        scenario: ['light-load', 'normal-load', 'stress-test']
        
    steps:
      - name: 'Checkout Code'
        uses: actions/checkout@v5

      - name: 'Setup Node.js'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 'Install Dependencies'
        run: npm ci --prefer-offline --no-audit --no-fund

      - name: 'Download Build Artifacts'
        uses: actions/download-artifact@v4
        with:
          name: build-output

      - name: 'Setup Test Database'
        run: |
          docker run --name load-test-postgres -e POSTGRES_USER=test -e POSTGRES_PASSWORD=test -e POSTGRES_DB=testdb -p 5432:5432 -d postgres:15-alpine
          sleep 10

      - name: 'Start Application'
        run: |
          npm start &
          sleep 30
          curl -f http://localhost:3000/api/health || exit 1
        env:
          DATABASE_URL: "postgresql://test:test@localhost:5432/testdb"
          NEXTAUTH_SECRET: "test-secret-for-ci"
          NEXTAUTH_URL: "http://localhost:3000"

      - name: 'Install Artillery'
        run: npm install --no-save artillery

      - name: 'Run Load Test - Light Load'
        if: matrix.scenario == 'light-load'
        run: |
          npx artillery quick --count 10 --num 5 http://localhost:3000 > artillery-light-load.json

      - name: 'Run Load Test - Normal Load'
        if: matrix.scenario == 'normal-load'
        run: |
          npx artillery quick --count 50 --num 10 http://localhost:3000 > artillery-normal-load.json

      - name: 'Run Load Test - Stress Test'
        if: matrix.scenario == 'stress-test'
        run: |
          npx artillery quick --count 100 --num 20 http://localhost:3000 > artillery-stress-test.json

      - name: 'Install K6'
        run: |
          curl -s https://dl.k6.io/key.gpg | sudo apt-key add -
          echo "deb https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: 'Run K6 Load Test'
        run: |
          cat << 'EOF' > k6-test.js
          import http from 'k6/http';
          import { check, sleep } from 'k6';
          
          export let options = {
            scenarios: {
              '${{ matrix.scenario }}': {
                executor: 'ramping-vus',
                startVUs: ${{ matrix.scenario == 'light-load' && '5' || matrix.scenario == 'normal-load' && '10' || '20' }},
                stages: [
                  { duration: '2m', target: ${{ matrix.scenario == 'light-load' && '10' || matrix.scenario == 'normal-load' && '25' || '50' }} },
                  { duration: '${{ github.event.inputs.test_duration || '5' }}m', target: ${{ matrix.scenario == 'light-load' && '10' || matrix.scenario == 'normal-load' && '25' || '50' }} },
                  { duration: '2m', target: 0 },
                ],
              },
            },
            thresholds: {
              http_req_duration: ['p(95)<2000'],
              http_req_failed: ['rate<0.1'],
            },
          };
          
          export default function () {
            let response = http.get('http://localhost:3000/');
            check(response, {
              'status is 200': (r) => r.status === 200,
              'response time < 2000ms': (r) => r.timings.duration < 2000,
            });
            
            // Test API endpoints
            response = http.get('http://localhost:3000/api/health');
            check(response, {
              'health check status is 200': (r) => r.status === 200,
            });
            
            sleep(1);
          }
          EOF
          
          k6 run --out json=k6-results-${{ matrix.scenario }}.json k6-test.js

      - name: 'Upload Load Test Results'
        uses: actions/upload-artifact@v4
        with:
          name: load-test-results-${{ matrix.scenario }}
          path: |
            artillery-*.json
            k6-results-*.json
          retention-days: 30

  # Memory and CPU profiling
  performance-profiling:
    name: 'Performance Profiling'
    runs-on: ubuntu-latest
    needs: [build-for-testing]
    if: github.event.inputs.test_type != 'lighthouse-only' && github.event.inputs.test_type != 'bundle-analysis-only'
    
    steps:
      - name: 'Checkout Code'
        uses: actions/checkout@v5

      - name: 'Setup Node.js'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: 'Install Dependencies'
        run: npm ci --prefer-offline --no-audit --no-fund

      - name: 'Download Build Artifacts'
        uses: actions/download-artifact@v4
        with:
          name: build-output

      - name: 'Setup Test Database'
        run: |
          docker run --name profile-postgres -e POSTGRES_USER=test -e POSTGRES_PASSWORD=test -e POSTGRES_DB=testdb -p 5432:5432 -d postgres:15-alpine
          sleep 10

      - name: 'Install Profiling Tools'
        run: |
          npm install --no-save clinic autocannon

      - name: 'Run CPU Profiling'
        run: |
          # Start the application with CPU profiling
          npx clinic doctor --on-port 'npx autocannon -c 10 -d 60 http://localhost:$PORT/' -- npm start
        env:
          DATABASE_URL: "postgresql://test:test@localhost:5432/testdb"
          NEXTAUTH_SECRET: "test-secret-for-ci"
          NEXTAUTH_URL: "http://localhost:3000"
          PORT: 3000

      - name: 'Run Memory Profiling'
        run: |
          # Start the application with memory profiling
          npx clinic heapprofiler --on-port 'npx autocannon -c 10 -d 60 http://localhost:$PORT/' -- npm start
        env:
          DATABASE_URL: "postgresql://test:test@localhost:5432/testdb"
          NEXTAUTH_SECRET: "test-secret-for-ci"
          NEXTAUTH_URL: "http://localhost:3000"
          PORT: 3001

      - name: 'Upload Profiling Results'
        uses: actions/upload-artifact@v4
        with:
          name: performance-profiling-results
          path: |
            .clinic/
            *.html
          retention-days: 30

  # Performance report generation
  performance-report:
    name: 'Performance Report'
    runs-on: ubuntu-latest
    needs: [build-for-testing, bundle-analysis, lighthouse-testing, load-testing, performance-profiling]
    if: always()
    
    steps:
      - name: 'Download All Test Results'
        uses: actions/download-artifact@v4
        with:
          path: performance-results

      - name: 'Generate Performance Report'
        run: |
          echo "# 🚀 Performance Test Report" > performance-report.md
          echo "" >> performance-report.md
          echo "**Test Date:** $(date -u)" >> performance-report.md
          echo "**Repository:** ${{ github.repository }}" >> performance-report.md
          echo "**Branch/Tag:** ${{ github.ref }}" >> performance-report.md
          echo "**Commit:** ${{ github.sha }}" >> performance-report.md
          echo "**Build Time:** ${{ needs.build-for-testing.outputs.build-time }} seconds" >> performance-report.md
          echo "" >> performance-report.md
          
          echo "## 📊 Test Results Summary" >> performance-report.md
          echo "" >> performance-report.md
          echo "| Test Type | Status | Duration |" >> performance-report.md
          echo "|-----------|--------|----------|" >> performance-report.md
          echo "| Build | ${{ needs.build-for-testing.result == 'success' && '✅ Passed' || '❌ Failed' }} | ${{ needs.build-for-testing.outputs.build-time }}s |" >> performance-report.md
          echo "| Bundle Analysis | ${{ needs.bundle-analysis.result == 'success' && '✅ Passed' || needs.bundle-analysis.result == 'failure' && '❌ Failed' || '⏩ Skipped' }} | - |" >> performance-report.md
          echo "| Lighthouse | ${{ needs.lighthouse-testing.result == 'success' && '✅ Passed' || needs.lighthouse-testing.result == 'failure' && '❌ Failed' || '⏩ Skipped' }} | - |" >> performance-report.md
          echo "| Load Testing | ${{ needs.load-testing.result == 'success' && '✅ Passed' || needs.load-testing.result == 'failure' && '❌ Failed' || '⏩ Skipped' }} | - |" >> performance-report.md
          echo "| Profiling | ${{ needs.performance-profiling.result == 'success' && '✅ Passed' || needs.performance-profiling.result == 'failure' && '❌ Failed' || '⏩ Skipped' }} | - |" >> performance-report.md
          
          echo "" >> performance-report.md
          echo "## 🎯 Performance Insights" >> performance-report.md
          echo "" >> performance-report.md
          
          if [ "${{ needs.build-for-testing.outputs.build-time }}" -gt 120 ]; then
            echo "⚠️ **Build time is longer than expected (> 2 minutes)**" >> performance-report.md
          else
            echo "✅ Build time is within acceptable range" >> performance-report.md
          fi
          
          echo "" >> performance-report.md
          echo "## 📈 Recommendations" >> performance-report.md
          echo "" >> performance-report.md
          echo "- Monitor bundle size growth over time" >> performance-report.md
          echo "- Optimize images and static assets" >> performance-report.md
          echo "- Consider implementing code splitting for large components" >> performance-report.md
          echo "- Review database query performance" >> performance-report.md
          echo "- Implement caching strategies for frequently accessed data" >> performance-report.md
          
          cat performance-report.md

      - name: 'Upload Performance Report'
        uses: actions/upload-artifact@v4
        with:
          name: performance-test-report
          path: performance-report.md
          retention-days: 90

      - name: 'Add Performance Comment (PR only)'
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('performance-report.md', 'utf8');
            
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });

      - name: 'Performance Test Summary'
        run: |
          echo "🏁 Performance testing completed!"
          echo "Build Time: ${{ needs.build-for-testing.outputs.build-time }}s"
          echo "Check artifacts for detailed results and reports."